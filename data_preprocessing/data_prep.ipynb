{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_lambda = boto3.client('lambda', region_name='us-east-1')\n",
    "iam_client = boto3.client('iam')\n",
    "role = iam_client.get_role(RoleName='LabRole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds = boto3.client('rds')\n",
    "\n",
    "# READ IN RDS\n",
    "# Connect to db with mysql.connector\n",
    "ENDPOINT = '' ## NEED THESE FROM LOIZOS CODE FOR RDS\n",
    "PORT = ''\n",
    "import mysql.connector\n",
    "conn =  mysql.connector.connect(host=ENDPOINT,\n",
    "                                user=\"username\",\n",
    "                                passwd=\"password\", \n",
    "                                port=PORT, \n",
    "                                database='books')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or update lambda function\n",
    "\n",
    "# Open our Zipped directory\n",
    "with open('./deployment-packages/lamda_function.zip', 'rb') as f:\n",
    "    lambda_zip = f.read()\n",
    "\n",
    "try:\n",
    "    # If function hasn't yet been created, create it\n",
    "    response = aws_lambda.create_function(\n",
    "        FunctionName='scrape_books',\n",
    "        Runtime='python3.9',\n",
    "        Role=role['Role']['Arn'],\n",
    "        Handler='lambda_function.lambda_handler',\n",
    "        Code=dict(ZipFile=lambda_zip),\n",
    "        Timeout=300\n",
    "    )\n",
    "except aws_lambda.exceptions.ResourceConflictException:\n",
    "    # If function already exists, update it based on zip\n",
    "    # file contents\n",
    "    response = aws_lambda.update_function_code(\n",
    "    FunctionName='scrape_books',\n",
    "    ZipFile=lambda_zip\n",
    "    )\n",
    "\n",
    "lambda_arn = response['FunctionArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step function\n",
    "\n",
    "sfn = boto3.client('stepfunctions')\n",
    "\n",
    "def make_def(lambda_arn):\n",
    "    definition = {\n",
    "      \"Comment\": \"My State Machine\",\n",
    "      \"StartAt\": \"Map\",\n",
    "      \"States\": {\n",
    "        \"Map\": {\n",
    "          \"Type\": \"Map\",\n",
    "          \"End\": True,\n",
    "          \"Iterator\": {\n",
    "            \"StartAt\": \"Lambda Invoke\",\n",
    "            \"States\": {\n",
    "              \"Lambda Invoke\": {\n",
    "                \"Type\": \"Task\",\n",
    "                \"Resource\": \"arn:aws:states:::lambda:invoke\",\n",
    "                \"OutputPath\": \"$.Payload\",\n",
    "                \"Parameters\": {\n",
    "                  \"Payload.$\": \"$\",\n",
    "                  \"FunctionName\": lambda_arn\n",
    "                },\n",
    "                \"Retry\": [\n",
    "                  {\n",
    "                    \"ErrorEquals\": [\n",
    "                      \"Lambda.ServiceException\",\n",
    "                      \"Lambda.AWSLambdaException\",\n",
    "                      \"Lambda.SdkClientException\",\n",
    "                      \"Lambda.TooManyRequestsException\",\n",
    "                      \"States.TaskFailed\"\n",
    "                    ],\n",
    "                    \"IntervalSeconds\": 2,\n",
    "                    \"MaxAttempts\": 6,\n",
    "                    \"BackoffRate\": 2\n",
    "                  }\n",
    "                ],\n",
    "                \"End\": True\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    return definition\n",
    "    \n",
    "sf_def = make_def(lambda_arn)\n",
    "\n",
    "try:\n",
    "    response = sfn.create_state_machine(\n",
    "        name='scrape_books_sm',\n",
    "        definition=json.dumps(sf_def),\n",
    "        roleArn=role['Role']['Arn'],\n",
    "        type='EXPRESS'\n",
    "    )\n",
    "except sfn.exceptions.StateMachineAlreadyExists:\n",
    "    response = sfn.list_state_machines()\n",
    "    state_machine_arn = [sm['stateMachineArn'] \n",
    "                         for sm in response['stateMachines'] \n",
    "                         if sm['name'] == 'scrape_books_sm'][0]\n",
    "    response = sfn.update_state_machine(\n",
    "        stateMachineArn=state_machine_arn,\n",
    "        definition=json.dumps(sf_def),\n",
    "        roleArn=role['Role']['Arn']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sfn.list_state_machines()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEED CODE HERE TO READ IN SQL INFORMATION AND DIVIDE BETWEEN BATCHES\n",
    "# do select query on books table to check that data was scraped and ingested in db\n",
    "cur.execute(\"\"\"SELECT * from books\"\"\")\n",
    "# divide scraped links in batches to pass to lambda \n",
    "batch_size = 50\n",
    "n = len(cur) // batch_size # subdivide list of urls into 50 equal batches\n",
    "urls_to_scrape_batches = [{'urls': cur[i:i + n]}\n",
    "                          for i in range(0, len(cur), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get arn for Step Function state machine\n",
    "state_machine_arn = [sm['stateMachineArn'] \n",
    "                     for sm in response['stateMachines'] \n",
    "                     if sm['name'] == 'scrape_books_sm'][0]\n",
    "\n",
    "# generate test data to pass as input\n",
    "# \"Map\" will automatically invoke a separate Lambda function\n",
    "# to process each dictionary in the list (50 concurrently)\n",
    "\n",
    "data = urls_to_scrape_batches[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async; perhaps writing results to db and don't need to wait for execution to finish before moving on with code\n",
    "response = sfn.start_execution(\n",
    "    stateMachineArn=state_machine_arn,\n",
    "    name='async_test',\n",
    "    input=json.dumps(urls_to_scrape_batches)\n",
    ")\n",
    "\n",
    "print(response) # no results returned for async option\n",
    "# Can go into logs in Cloud Watch and see execution results (Express SF workflow)\n",
    "# Note that Standard Step Function workflow allows us to audit results via Boto3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to db using mysql.connector\n",
    "import mysql.connector\n",
    "conn =  mysql.connector.connect(host=ENDPOINT,\n",
    "                                user=\"username\",\n",
    "                                passwd=\"password\", \n",
    "                                port=PORT, \n",
    "                                database='books')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
